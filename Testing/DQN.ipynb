{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The system cannot find the path specified.\n",
      "The system cannot find the path specified.\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5b3e59a836ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0minstallWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mauth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[0mauthorizeWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mcreateDriveDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-5b3e59a836ee>\u001b[0m in \u001b[0;36mauth\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# def installWrapper():\n",
    "#     # Install a Drive FUSE wrapper.\n",
    "#     # https://github.com/astrada/google-drive-ocamlfuse\n",
    "#     !apt-get update -qq 2>&1 > /dev/null\n",
    "#     !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "#     !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "#     !apt-get update -qq 2>&1 > /dev/null\n",
    "#     !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "    \n",
    "# def auth():\n",
    "#     from google.colab import auth\n",
    "#     auth.authenticate_user()\n",
    "    \n",
    "# def authorizeWrapper():\n",
    "#     # Generate creds for the Drive FUSE library.\n",
    "#     from google.colab import output\n",
    "#     from oauth2client.client import GoogleCredentials\n",
    "#     import time\n",
    "#     creds = GoogleCredentials.get_application_default()\n",
    "#     import getpass\n",
    "#     # Determine if Drive Fuse credential setup is already complete.\n",
    "#     fuse_credentials_configured = False\n",
    "#     with output.temporary():\n",
    "#       !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1\n",
    "#       # _exit_code is set to the result of the last \"!\" command.\n",
    "#       fuse_credentials_configured = _exit_code == 0\n",
    "#     # Sleep for a short period to ensure that the previous output has been cleared.\n",
    "#     time.sleep(1)\n",
    "#     if fuse_credentials_configured:\n",
    "#       print('Drive FUSE credentials already configured!')\n",
    "#     else:\n",
    "#       # Work around misordering of STREAM and STDIN in Jupyter.\n",
    "#       # https://github.com/jupyter/notebook/issues/3159\n",
    "#       prompt = !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "#       vcode = getpass.getpass(prompt[0] + '\\n\\nEnter verification code: ')\n",
    "#       !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "    \n",
    "# def createDriveDir():\n",
    "#     !mkdir -p drive\n",
    "#     !google-drive-ocamlfuse drive\n",
    "    \n",
    "# installWrapper()\n",
    "# auth()\n",
    "# authorizeWrapper()\n",
    "# createDriveDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import sgd\n",
    "from itertools import product as possibleIterations\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQAgent:\n",
    "    def __init__(self, state_size, action_space):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = 81 # todo check, looks shady\n",
    "        self.memory = deque(maxlen=200000) # chaged this from 2000\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.05 # changed this from 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        self.action_space = actions_space\n",
    "\n",
    "    def get_action_from_prediction(self, predict):\n",
    "        return self.action_space[np.argmax(predict[0])]\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(100, input_dim=self.state_size, activation='relu')) # changed layer count from 24\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='softmax')) # changed this from linear\n",
    "        model.compile(loss='mse', optimizer=sgd(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        action_index = self.action_space.tolist().index(action.tolist())\n",
    "        self.memory.append((state, action_index, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return self.action_space[np.random.choice([i for i in range(len(self.action_space))])]\n",
    "        act_values = self.model.predict(state) # what does this return\n",
    "        return self.get_action_from_prediction(act_values)\n",
    "\n",
    "    def replay(self, batch_size, agent2):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * np.amax(agent2.model.predict(next_state)[0])) # Returns q-values\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 1000\n",
    "\n",
    "def get_actions():\n",
    "    possibleTorques = np.array([-1.0, 0.0, 1.0])\n",
    "    possibleActions = np.array(list(possibleIterations(possibleTorques, possibleTorques, possibleTorques, possibleTorques)))\n",
    "    return possibleActions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make('BipedalWalker-v2')\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    actions_space = get_actions()\n",
    "    action_size = len(actions_space)\n",
    "    agent = DeepQAgent(state_size, actions_space)\n",
    "    agent2 = DeepQAgent(state_size, actions_space)\n",
    "    done = False\n",
    "    batch_size = 32\n",
    "    c = 0\n",
    "    recent_average = deque(maxlen = 100)\n",
    "    for e in range(EPISODES):\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        total_reward = 0\n",
    "        for time in range(500):\n",
    "            c += 1\n",
    "            #env.render()\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                      .format(e, EPISODES, total_reward, agent.epsilon))\n",
    "                recent_average.append(total_reward)\n",
    "                print(\"c = \", c, \" Recent Average = \", sum(recent_average)/len(recent_average))\n",
    "                break\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size, agent2)\n",
    "            if c >= 1000:\n",
    "                print('updating model')\n",
    "                c = 0\n",
    "                # agent2 = copy.deepcopy(agent)\n",
    "                agent2.model.set_weights(agent.model.get_weights())\n",
    "        if e % 50 == 0:\n",
    "            agent.save(\"drive/AIProject/Bipedal-dqn-testing.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
